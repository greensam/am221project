{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString\n",
    "import pandas as pd\n",
    "import StringIO\n",
    "import urllib\n",
    "from datetime import date, datetime, timedelta\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.stats.stats import pearsonr\n",
    "import math\n",
    "import sys\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple lambda function\n",
    "def split(x, num):\n",
    "    return int(x.split('-')[num])\n",
    "\n",
    "# Write a function that scrapes the team trend graph for each game\n",
    "def ncaatrendgraph(gameid):\n",
    "\n",
    "    # Scrape the reference team page\n",
    "    url = 'http://espn.go.com/mens-college-basketball/playbyplay?gameId=' + str(gameid)\n",
    "    html = urllib.urlopen(url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\") \n",
    "\n",
    "    # Identify which team is which from the basic page\n",
    "    teams = soup.find_all('div', {'class', \"team-container\"})\n",
    "\n",
    "    away = str(teams[0].find('span', {'class', 'long-name'}).contents[0]).split(';')[0]\n",
    "    home = str(teams[1].find('span', {'class', 'long-name'}).contents[0]).split(';')[0]\n",
    "\n",
    "    # # Run through the table and get all the relevant events from that quarter\n",
    "    qes = []\n",
    "    tps = len(soup.find_all('table'))-1\n",
    "    for num in range(1,tps):\n",
    "        for item in soup.find_all('table')[num].find_all('tr')[1:]:\n",
    "            event = []\n",
    "            for td in item.find_all('td'):\n",
    "                if len(td.contents) > 0:\n",
    "                    if 'img' in str(td.contents[0]):\n",
    "                        event.append(str(td.contents[0]['src']).split('/')[-1].split('.')[0].upper())\n",
    "                    else:\n",
    "                        if ':' in str(td.contents[0]):\n",
    "                            if num > 2:\n",
    "                                minutes = 4-int(td.contents[0].split(':')[0]) + 40 + ((num-3)*5)\n",
    "                            else:\n",
    "                                minutes = 19-int(td.contents[0].split(':')[0]) +((num-1)*20)\n",
    "                            seconds = 60-int(td.contents[0].split(':')[1])\n",
    "\n",
    "                            # Make an adjustment for exact minute calculations\n",
    "                            if seconds == 60:\n",
    "                                minutes = minutes + 1\n",
    "                                seconds = 0\n",
    "\n",
    "                            event.append(minutes)\n",
    "                            event.append(seconds)\n",
    "                        else:\n",
    "                            event.append(str(td.contents[0]))\n",
    "            qes.append(event)\n",
    "\n",
    "    # Make this data into a Dataframe\n",
    "    bsd = pd.DataFrame(qes, columns = ['Minutes', 'Seconds', 'Team', 'Event', 'Score'])\n",
    "    bsd[away] = bsd['Score'].apply(lambda x: split(x, 0))\n",
    "    bsd[home] = bsd['Score'].apply(lambda x: split(x, 1))\n",
    "    bsd = bsd.drop('Score', 1)\n",
    "\n",
    "    # # Write a quick function converting the minutes and seconds to a percentage\n",
    "    if (tps) == 3:\n",
    "        numminutes = 40\n",
    "    else:\n",
    "        numminutes = 40 + 5*(tps-3)\n",
    "    lengame = numminutes*60.0\n",
    "    bsd['PercDone'] = [float(100*round((mins*60+sec)/lengame,4)) for (mins, sec) in zip(bsd['Minutes'], bsd['Seconds'])]\n",
    "    return bsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write a function that processes the events that happen during this period\n",
    "\"\"\"\n",
    "Gamedata: The dataframe containing all the data above\n",
    "Start: The time at which you'd like to start looking (%H:%M, ex. 7:20 (EST))\n",
    "Finish: The time at which you'd like to stop looking (see above)\n",
    "\"\"\"\n",
    "def gamevents(gamedata, start, finish, begin, end):\n",
    "    start_conv = datetime.strptime(start, '%H:%M')\n",
    "    finish_conv = datetime.strptime(finish, '%H:%M')\n",
    "    \n",
    "    # Make quick sanity checks\n",
    "    if start_conv < begin:\n",
    "        start_conv = begin\n",
    "    if finish_conv > end:\n",
    "        finish_conv = end\n",
    "    \n",
    "    # Check where each event is in relation to halftime\n",
    "    sloc, endloc = 0, 0\n",
    "    htbegin = begin + timedelta(0, (end-begin).seconds/2 - lenhalf/2)\n",
    "    htend = begin + timedelta(0,(end-begin).seconds/2 + lenhalf/2)\n",
    "    if start_conv > htend:\n",
    "        sloc = 1\n",
    "    if finish_conv > htend:\n",
    "        endloc = 1\n",
    "        \n",
    "    # Assume for now that both are on the same side of halftime\n",
    "    if endloc == 0:\n",
    "        ttb1, ttb2 = (start_conv - begin).seconds, (finish_conv - begin).seconds\n",
    "        perc1, perc2 = round(100*(1.0*ttb1)/(2*(htbegin-begin).seconds),2), round(100*(1.0*ttb2)/(2*(htbegin-begin).seconds),2)\n",
    "    elif endloc == 1:\n",
    "        ttb1, ttb2 = (start_conv - htend).seconds, (finish_conv - htend).seconds\n",
    "        perc1, perc2 = round(100*(1.0*ttb1)/(end-htend).seconds,2)+50, round(100*(1.0*ttb2)/(end-htend).seconds,2)+50\n",
    "    \n",
    "    # Grab the data from the gamedata\n",
    "    return gdata[(gdata['PercDone'] > perc1) & (gdata['PercDone'] < perc2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Large function that will return to you the relevant game events and then a list of tweets (with their times) \n",
    "from the time period that you specify. Currently works by submitting actual times.\n",
    "\n",
    "Inputs:\n",
    "gp1: The first game participant\n",
    "gp2: The second game participant\n",
    "tp1: Beginning of time period (%H:%M, ex. 7:20), measured by EST\n",
    "tp2: End of time period\n",
    "\n",
    "Outputs:\n",
    "dt1: Dataframe containing all the game events from that period \n",
    "dt2: Dataframe containing the tweets from that period\n",
    "\"\"\"\n",
    "\n",
    "def databytime(gp1, gp2, tp1, tp2):\n",
    "    \n",
    "    # Get the important metadata and define a useful constant\n",
    "    gmdat = pd.read_csv(\"GameMetadata.csv\")\n",
    "    metadat = gmdat[((gmdat['Team1'] == gp1) | (gmdat['Team1'] == gp2)) & ((gmdat['Team2'] == gp1) | (gmdat['Team2'] == gp2))]\n",
    "    eid = metadat['espn_id'].iloc[0]\n",
    "    begin, end = datetime.strptime(metadat['Start'].iloc[0], '%H:%M'), datetime.strptime(metadat['End'].iloc[0], '%H:%M')\n",
    "    lenhalf = 20*60\n",
    "    \n",
    "    # Grab the game data for the time period\n",
    "    gdata = ncaatrendgraph(eid)\n",
    "    dt1 = gamevents(gdata, tp1, tp2, begin, end)\n",
    "    \n",
    "    # Grab the relevant data from the twitter file\n",
    "    fname = metadat['Filename'].iloc[0]\n",
    "    tweets =  pd.read_csv(fname)\n",
    "    tweets['time_chg'] = tweets['time'].apply(lambda x: x.split(' ')[3])\n",
    "    \n",
    "    indices = []\n",
    "    for num in range(0, len(tweets['time_chg'])):\n",
    "        tweetstamp = datetime.strptime(tweets['time_chg'].iloc[num], \"%H:%M:%S\") - timedelta(hours=4)\n",
    "        if (tweetstamp > begin) and (tweetstamp < end):\n",
    "            if (tweetstamp > datetime.strptime(tp1, '%H:%M')) and (tweetstamp < datetime.strptime(tp2, '%H:%M')):\n",
    "                indices.append(num)\n",
    "    dt2 = tweets[tweets.index.isin(indices)]\n",
    "    \n",
    "    return dt1, dt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Large function that will return to you the relevant game events and then a list of tweets (with their times) \n",
    "from the time period that you specify. Currently works by submitting actual times.\n",
    "\n",
    "Inputs:\n",
    "gp1: The first game participant\n",
    "gp2: The second game participant\n",
    "gtp1: Beginning of game time period (20:00 -- Halftime, 35:00 -- After halftime)\n",
    "gtp2: End of game time period\n",
    "\n",
    "Outputs:\n",
    "dt1: Dataframe containing all the game events from that period \n",
    "dt2: Dataframe containing the tweets from that period\n",
    "\"\"\"\n",
    "def databygametime(gp1, gp2, gtp1, gtp2):\n",
    "    \n",
    "    # Get the important metadata and define a useful constant\n",
    "    gmdat = pd.read_csv(\"GameMetadata.csv\")\n",
    "    metadat = gmdat[((gmdat['Team1'] == gp1) | (gmdat['Team1'] == gp2)) & ((gmdat['Team2'] == gp1) | (gmdat['Team2'] == gp2))]\n",
    "    eid = metadat['espn_id'].iloc[0]\n",
    "    begin, end = datetime.strptime(metadat['Start'].iloc[0], '%H:%M'), datetime.strptime(metadat['End'].iloc[0], '%H:%M')\n",
    "    lenhalf = 20*60\n",
    "    htbegin = begin + timedelta(0, (end-begin).seconds/2 - lenhalf/2)\n",
    "    htend = begin + timedelta(0,(end-begin).seconds/2 + lenhalf/2)\n",
    "    \n",
    "    # Grab the initial data by mapping gametimes to parts of the game\n",
    "    fullgamedat = ncaatrendgraph(eid)\n",
    "    bmin, bsec = gtp1.split(\":\")\n",
    "    emin, esec = gtp2.split(\":\")\n",
    "    btot = int(bmin)*60 + int(bsec)\n",
    "    etot = int(emin)*60 + int(bsec)\n",
    "    maxmin = np.max(fullgamedat['Minutes'])*60\n",
    "    bperc, eperc = (100.0*btot)/maxmin, (100.0*etot)/maxmin\n",
    "    dt1 = fullgamedat[(fullgamedat['PercDone'] >= bperc) & (fullgamedat['PercDone'] <= eperc)]\n",
    "    \n",
    "    # Use the percentages of the game to map gametimes to actual times\n",
    "    acttimes = []\n",
    "    for item in [bperc, eperc]:\n",
    "        hperc = (item*2)/100\n",
    "        if item <= 50.0:\n",
    "            secdelt = round((htbegin-begin).seconds*hperc,0)\n",
    "            acttimes.append(secdelt)\n",
    "        elif item > 50.0:\n",
    "            secdelt = round((end-htend).seconds*(hperc-1.0) + (htend-begin).seconds,0)\n",
    "            acttimes.append(secdelt)\n",
    "    \n",
    "    # Convert the time to usable timedelt objects\n",
    "    tp1, tp2 = begin + timedelta(0,seconds = acttimes[0]), begin + timedelta(0,seconds = acttimes[1])\n",
    "    tp1, tp2 = str(tp1).split(\" \")[1], str(tp2).split(\" \")[1]\n",
    "    \n",
    "    # Get the relevant Tweets over that time period using identical code to before\n",
    "    fname = metadat['Filename'].iloc[0]\n",
    "    tweets =  pd.read_csv(fname)\n",
    "    tweets['time_chg'] = tweets['time'].apply(lambda x: x.split(' ')[3])\n",
    "    \n",
    "    indices = []\n",
    "    for num in range(0, len(tweets['time_chg'])):\n",
    "        tweetstamp = datetime.strptime(tweets['time_chg'].iloc[num], \"%H:%M:%S\") - timedelta(hours=4)\n",
    "        if (tweetstamp > begin) and (tweetstamp < end):\n",
    "            if (tweetstamp > datetime.strptime(tp1, '%H:%M:%S')) and (tweetstamp < datetime.strptime(tp2, '%H:%M:%S')):\n",
    "                indices.append(num)\n",
    "    dt2 = tweets[tweets.index.isin(indices)]\n",
    "    \n",
    "    return dt1, dt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samp1, samp2 = databygametime('Virginia', 'Syracuse', '1:10', '22:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samp3, samp4 = databytime('Virginia', 'Syracuse', '18:10', '18:20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "\n",
    "# Relevance Classifier Below, Time Separation Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pd.read_csv(\"UVAcuse_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "virginia = [y for y in x['text'] if \"#Virginia\" in y or \"#UVA\" in y]\n",
    "syracuse = [y for y in x['text'] if \"#Syracuse\" in y]\n",
    "both = [y for y in x['text'] if \"#Syracuse\" in y and \"#Virginia\" in y]\n",
    "\n",
    "# Record the basic assumption that we just take the one that is mentioned first\n",
    "# Next steps\n",
    "    # 1. We want to combine list of names with list of hashtags that we care about (DONE)\n",
    "    # 2. We want to classify each Tweet based on whether it contains the hashtags or the player names as relevant\n",
    "    # 3. Classify to either team based on either the preponderance of hashtags or the first classifier\n",
    "    # 4. Wrap this all in a function that just takes a .csv as input and returns the relevant classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write a quick function that will grab the relevant roster items, given a team id\n",
    "def grabroster(teampage):\n",
    "    url = \"http://\" + teampage.split('team')[0] + 'team/stats' + teampage.split('team')[1]\n",
    "    html = urllib.urlopen(url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\") \n",
    "\n",
    "    names = []\n",
    "    for tr in soup.find_all('table')[0].find_all('tr')[2:9]:\n",
    "        for item in tr.find_all('td')[0:1]:\n",
    "            names.append(str(item.contents[0].contents[0]).split(' ')[1])\n",
    "    return names\n",
    "    \n",
    "# Write a function that will return two lists, each of which contains the last names of the top six players (as measured\n",
    "# by playing time), the name of the associated coach for the team, and the \n",
    "def relvtags(gameid):\n",
    "    gameid = 400873651\n",
    "    url = 'http://espn.go.com/mens-college-basketball/playbyplay?gameId=' + str(gameid)\n",
    "    html = urllib.urlopen(url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\") \n",
    "\n",
    "    # Identify which team is which from the basic page\n",
    "    teams = soup.find_all('div', {'class', \"team-container\"}) \n",
    "\n",
    "    # Find the links to the right pages\n",
    "    teamlinks = [str(\"espn.go.com\" + teams[0].find_all('a')[0]['href']), \n",
    "                 str(\"espn.go.com\" + teams[1].find_all('a')[0]['href'])]\n",
    "\n",
    "    # Grab the correct roster for the team\n",
    "    team1, team2 = grabroster(teamlinks[0]), grabroster(teamlinks[1])\n",
    "    coach1, coach2 = coachdict[int(teamlinks[0].split('/')[-1])], coachdict[int(teamlinks[1].split('/')[-1])]\n",
    "    team1.append(coach1.split(' ')[1])\n",
    "    team2.append(coach2.split(' ')[1])\n",
    "    print team1, team2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the relevant dictionaries for the stuff coming after\n",
    "coachurl = \"http://espn.go.com/mens-college-basketball/story/_/id/14967272/ranking-ncaa-tournament-coaches-players-1-68\"\n",
    "coachhtml = urllib.urlopen(coachurl)\n",
    "coachsoup = BeautifulSoup(coachhtml, \"html.parser\")\n",
    "\n",
    "# Create a useful dictionary for the ids and the coach\n",
    "coachdict = {}\n",
    "for item in coachsoup.find_all('strong'):\n",
    "    name = str(item.contents[0].split('. ')[1][:-2])\n",
    "    \n",
    "    # Get the associated teamid, throwing an exception for Southern (only non-linked team in the database)\n",
    "    if ',' not in name:\n",
    "        gid = int(item.find_all('a')[0]['href'].split('id/')[1].split('/')[0])\n",
    "    else:\n",
    "        gid = 2582\n",
    "        name = name.split(',')[0]\n",
    "    coachdict[gid] = name\n",
    "\n",
    "# Define a dict with tags for each team\n",
    "tagdict = {12: ['#Wildcats', '#Arizona', '#GoCats', '#BearDown', '#AZWildcats', '#watchus', '#APlayersProgram'],\n",
    "           25: ['#Cal', '#LetsDance', '#GoldenBears', '#GoBears', '#CalFamily'],\n",
    "           38: ['#Buffaloes', '#Colorado', '#GoBuffs'],\n",
    "           41: ['#Huskies', '#UConn', '#Connecticut', '#bleedblue', '#GoHuskies', '#UConnbasketball', '#UConnnation'],\n",
    "           43: ['#Bulldogs', '#Yale', '#OneIvy', '#YaleBasketball', '#GoYale'],\n",
    "           62: ['#RainbowWarriors', '#Hawaii', '#HawaiiMBB', '#RoadWarriors', '#GoBows'],\n",
    "           66: ['#Cyclones', '#IowaSt', '#IowaState', '#cyclONEnation'],\n",
    "           84: ['#Hoosiers', '#IU', '#ForIndiana', '#iubb'],\n",
    "           87: ['#NotreDame', '#NotDoneYet', '#FightingIrish'],\n",
    "           96: ['#Kentucky', '#Wildcats', '#Cats', '#BigBlueNation'],\n",
    "           107: ['#HolyCross', '#Crusaders', '#RiseTogether'],\n",
    "           120: ['#WeWill', '#Maryland', '#Terrapins'],\n",
    "           127: ['#Spartans', '#GoGreen', '#GoWhite', '#MSU', '#MichiganState'],\n",
    "           130: ['#Michigan', '#UMich', '#Wolverines', '#Squad100', '#GoBlue'],\n",
    "           150: ['#Duke', '#BlueDevils', '#GoDuke'],\n",
    "           153: ['#UNC', '#TarHeels', '#HeelsLockIn', '#UNCBBall'],\n",
    "           183: ['#Syracuse', '#OrangeCrush', '#CuseMode', '#StLouis'],\n",
    "           201: ['#Oklahoma', '#OU', '#Sooners', '#BuddyBuckets'],\n",
    "           204: ['#Beavers', '#OregonState', '#oregonstatebasketball', '#BeaverNation', '#GoBeavs'],\n",
    "           218: ['#Temple', '#Owls', '#BeatIowa', '#TUMBB'],\n",
    "           221: ['#Pittsburgh', '#Panthers', '#H2P'],\n",
    "           222: ['#Villanova', '#Nova', '#NovaMBB', '#NovaNation', '#LetsMarchNova'],\n",
    "           239: ['#Bears', '#Baylor', '#GoBears'],\n",
    "           245: ['#TexasA&M', '#Aggies', '#Gigem', '#TAMU', '#12thMan', '#AggieHoops'],\n",
    "           251: ['#UT', '#Longhorns', '#HookEm', '#Horns'],\n",
    "           254: ['#Utah', '#Utes', '#goutes', '#Playformore', '#BeatGonzaga'],\n",
    "           258: ['#Virginia', '#Cavaliers', '#Bulldogs', '#UVA', '#GoHoos'],\n",
    "           275: ['#Badgers', '#Wisconsin', '#MakeEmBelieve', '#Fieldof64', '#WisconsinBasketball'],\n",
    "           277: ['#WestVirginia', '#WVU', '#HailWV', '#PressVirginia', '#Mountaineers'],\n",
    "           2031: ['#LittleRocksTeam'],\n",
    "           2046: ['#AustinPeay', '#LetsGoPeay', '#16over1'],\n",
    "           2084: ['#Bison', '#Buffalo', '#UBBulls', '#UBDancing', '#HornsUp'],\n",
    "           2086: ['#Butler', '#Bulldogs', '#GoDawgs'],\n",
    "           2132: ['#Cincinnati', '#Cincy', '#BearCats', '#Dancin6'],\n",
    "           2168: ['#Dayton', '#Flyers', '#TrueTeam', '#GoFlyers'],\n",
    "           2250: ['#Zags', '#Gonzaga', '#GoZags', '#UnitedWeZag', '#zagup'],\n",
    "           2294: ['#Hawkeyes', '#Iowa'],\n",
    "           2305: ['#Jayhawks', '#kubball', '#Kansas', '#RockChalk'],\n",
    "           2390: ['#Hurricanes', '#Miami', '#BeatBuffalo', '#GoCanes'],\n",
    "           2393: ['#MiddleTennesseeState', '#MTSU', '#BlueRaiders', '#DancingRaiders'],\n",
    "           2427: ['#OurTownOurTeam', '#Bulldogs', '#Cinderella', '#UNCAsheville', '#Asheville'],\n",
    "           2460: ['#NorthernIowa', '#Panthers', '#PantherNation', '#UNI', '#UNIFight'],\n",
    "           2483: ['#Oregon', '#Ducks', '#GoDucks'],\n",
    "           2507: ['#Friars', '#PCBB', '#gofriars', '#pcbb', '#dunnions'],\n",
    "           2550: ['#SetonHall', '#HALLin', '#shbb', '#SHUnited'],\n",
    "           2571: ['#SDSU', '#Jackrabbits', '#MarchTogether'],\n",
    "           2603: ['#StJoes', '#Hawks', '#StJosephs', '#THWND'],\n",
    "           2617: ['#Lumberjacks', '#SFA', '#AxeEm'],\n",
    "           2670: ['#Rams', '#LetsGoVCU', '#VCU'],\n",
    "           2692: ['#Wildcats', '#WeberState', '#WeAreWeber', '#BigSkyMBB'],\n",
    "           2724: ['#Wildcats', '#Shockers', '#Shocktheworld', '#WichitaSt'],\n",
    "           2739: ['#RP40', '#HLMBB', '#ContinueTheRise', '#GreenBay'],\n",
    "           2752: ['#Xavier', '#Musketeers', '#LetsGoX', '#LetsMarch'],\n",
    "           2934: ['#CSUBelieve', '#AllRunners', '#CSUB']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a quick function that will grab the relevant roster items, given a team id\n",
    "def grabroster(teampage):\n",
    "    url = \"http://\" + teampage.split('team')[0] + 'team/stats' + teampage.split('team')[1]\n",
    "    html = urllib.urlopen(url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\") \n",
    "\n",
    "    names = []\n",
    "    for tr in soup.find_all('table')[0].find_all('tr')[2:9]:\n",
    "        for item in tr.find_all('td')[0:1]:\n",
    "            names.append(str(item.contents[0].contents[0]).split(' ')[1])\n",
    "    return names\n",
    "    \n",
    "# Write a function that will return two lists, each of which contains the last names of the top six players (as measured\n",
    "# by playing time), the name of the associated coach for the team, and the \n",
    "def relvtags(gameid):\n",
    "    url = 'http://espn.go.com/mens-college-basketball/playbyplay?gameId=' + str(gameid)\n",
    "    html = urllib.urlopen(url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\") \n",
    "\n",
    "    # Identify which team is which from the basic page\n",
    "    teams = soup.find_all('div', {'class', \"team-container\"}) \n",
    "\n",
    "    # Find the links to the right pages\n",
    "    teamlinks = [str(\"espn.go.com\" + teams[0].find_all('a')[0]['href']), \n",
    "                 str(\"espn.go.com\" + teams[1].find_all('a')[0]['href'])]\n",
    "\n",
    "    # Grab the correct roster for the team\n",
    "    x = []\n",
    "    for item in teamlinks:\n",
    "        team = grabroster(item)\n",
    "        gid = int(item.split('/')[-1])\n",
    "        team.append(coachdict[gid].split(' ')[1])\n",
    "        for tag in tagdict[gid]:\n",
    "            team.append(tag)\n",
    "            team.append(tag.split('#')[1])\n",
    "        x.append(team)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Go through and classify whether a text is in the tweet\n",
    "def textcheck(tweet, array):\n",
    "    relvs = []\n",
    "    for tagset in array:\n",
    "        counter = 0\n",
    "        for word in tagset:\n",
    "            if word in tweet:\n",
    "                counter += 1\n",
    "        # Check if anything showed up\n",
    "        if counter > 0:\n",
    "            relvs.append(1)\n",
    "            relvs.append(counter)\n",
    "        else:\n",
    "            relvs.append(0)\n",
    "            relvs.append(0)\n",
    "    return relvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-3691e16ecbc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelvtags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400873156\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-188-e3844a30218c>\u001b[0m in \u001b[0;36mrelvtags\u001b[0;34m(gameid)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mteamlinks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mteam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrabroster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mgid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mteam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoachdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-188-e3844a30218c>\u001b[0m in \u001b[0;36mgrabroster\u001b[0;34m(teampage)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mteampage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'team'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'team/stats'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mteampage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'team'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/bs4/__init__.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/bs4/__init__.pyc\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/bs4/builder/_htmlparser.pyc\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTMLParseError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             warnings.warn(RuntimeWarning(\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/HTMLParser.pyc\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \"\"\"\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/HTMLParser.pyc\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstarttagopen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# < + letter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/HTMLParser.pyc\u001b[0m in \u001b[0;36mparse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_startendtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDATA_CONTENT_ELEMENTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cdata_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/bs4/builder/_htmlparser.pyc\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, attrs)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mattr_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mattrvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\"\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/bs4/__init__.pyc\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, namespace, nsprefix, attrs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         tag = Tag(self, self.builder, name, namespace, nsprefix, attrs,\n\u001b[0;32m--> 404\u001b[0;31m                   self.currentTag, self._most_recent_element)\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/bs4/element.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parser, builder, name, namespace, prefix, attrs, parent, previous)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/bs4/element.pyc\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, parent, previous_element, next_element, previous_sibling, next_sibling)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         if (not previous_sibling\n\u001b[0;32m--> 210\u001b[0;31m             and self.parent is not None and self.parent.contents):\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0mprevious_sibling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Trial\n",
    "y = []\n",
    "for num in range(0, 100):\n",
    "    y.append(textcheck(x['text'].iloc[num], relvtags(400873156)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
