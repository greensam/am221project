{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import NavigableString\n",
    "import pandas as pd\n",
    "import StringIO\n",
    "import urllib\n",
    "from datetime import date, datetime, timedelta\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.stats.stats import pearsonr\n",
    "import math\n",
    "import sys\n",
    "from sentiment import Classifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple lambda function\n",
    "def split(x, num):\n",
    "    return int(x.split('-')[num])\n",
    "\n",
    "# Write a function that scrapes the team trend graph for each game\n",
    "def ncaatrendgraph(gameid):\n",
    "\n",
    "    # Scrape the reference team page\n",
    "    url = 'http://espn.go.com/mens-college-basketball/playbyplay?gameId=' + str(gameid)\n",
    "    html = urllib.urlopen(url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\") \n",
    "\n",
    "    # Identify which team is which from the basic page\n",
    "    teams = soup.find_all('div', {'class', \"team-container\"})\n",
    "\n",
    "    away = str(teams[0].find('span', {'class', 'long-name'}).contents[0]).split(';')[0]\n",
    "    home = str(teams[1].find('span', {'class', 'long-name'}).contents[0]).split(';')[0]\n",
    "\n",
    "    # # Run through the table and get all the relevant events from that quarter\n",
    "    qes = []\n",
    "    tps = len(soup.find_all('table'))-1\n",
    "    for num in range(1,tps):\n",
    "        for item in soup.find_all('table')[num].find_all('tr')[1:]:\n",
    "            event = []\n",
    "            for td in item.find_all('td'):\n",
    "                if len(td.contents) > 0:\n",
    "                    if 'img' in str(td.contents[0]):\n",
    "                        event.append(str(td.contents[0]['src']).split('/')[-1].split('.')[0].upper())\n",
    "                    else:\n",
    "                        if ':' in str(td.contents[0]):\n",
    "                            if num > 2:\n",
    "                                minutes = 4-int(td.contents[0].split(':')[0]) + 40 + ((num-3)*5)\n",
    "                            else:\n",
    "                                minutes = 19-int(td.contents[0].split(':')[0]) +((num-1)*20)\n",
    "                            seconds = 60-int(td.contents[0].split(':')[1])\n",
    "\n",
    "                            # Make an adjustment for exact minute calculations\n",
    "                            if seconds == 60:\n",
    "                                minutes = minutes + 1\n",
    "                                seconds = 0\n",
    "\n",
    "                            event.append(minutes)\n",
    "                            event.append(seconds)\n",
    "                        else:\n",
    "                            event.append(str(td.contents[0]))\n",
    "            qes.append(event)\n",
    "\n",
    "    # Make this data into a Dataframe\n",
    "    bsd = pd.DataFrame(qes, columns = ['Minutes', 'Seconds', 'Team', 'Event', 'Score'])\n",
    "    bsd[away] = bsd['Score'].apply(lambda x: split(x, 0))\n",
    "    bsd[home] = bsd['Score'].apply(lambda x: split(x, 1))\n",
    "    bsd = bsd.drop('Score', 1)\n",
    "\n",
    "    # # Write a quick function converting the minutes and seconds to a percentage\n",
    "    if (tps) == 3:\n",
    "        numminutes = 40\n",
    "    else:\n",
    "        numminutes = 40 + 5*(tps-3)\n",
    "    lengame = numminutes*60.0\n",
    "    bsd['PercDone'] = [float(100*round((mins*60+sec)/lengame,4)) for (mins, sec) in zip(bsd['Minutes'], bsd['Seconds'])]\n",
    "    return bsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write a function that processes the events that happen during this period\n",
    "\"\"\"\n",
    "Gamedata: The dataframe containing all the data above\n",
    "Start: The time at which you'd like to start looking (%H:%M, ex. 7:20 (EST))\n",
    "Finish: The time at which you'd like to stop looking (see above)\n",
    "\"\"\"\n",
    "def gamevents(gamedata, start, finish, begin, end):\n",
    "    start_conv = datetime.strptime(start, '%H:%M')\n",
    "    finish_conv = datetime.strptime(finish, '%H:%M')\n",
    "        \n",
    "    # Make quick sanity checks\n",
    "    if start_conv < begin:\n",
    "        start_conv = begin\n",
    "    if finish_conv > end:\n",
    "        finish_conv = end\n",
    "    # Check where each event is in relation to halftime\n",
    "    sloc, endloc = 0, 0\n",
    "    lenhalf = 20*60\n",
    "    htbegin = begin + timedelta(0, (end-begin).seconds/2 - lenhalf/2)\n",
    "    htend = begin + timedelta(0,(end-begin).seconds/2 + lenhalf/2)\n",
    "    if start_conv > htend:\n",
    "        sloc = 1\n",
    "    if finish_conv > htend:\n",
    "        endloc = 1\n",
    "        \n",
    "    # Assume for now that both are on the same side of halftime\n",
    "    if endloc == 0:\n",
    "        ttb1, ttb2 = (start_conv - begin).seconds, (finish_conv - begin).seconds\n",
    "        perc1, perc2 = round(100*(1.0*ttb1)/(2*(htbegin-begin).seconds),2), round(100*(1.0*ttb2)/(2*(htbegin-begin).seconds),2)\n",
    "    elif endloc == 1:\n",
    "        ttb1, ttb2 = (start_conv - htend).seconds, (finish_conv - htend).seconds\n",
    "        perc1, perc2 = round(100*(1.0*ttb1)/(end-htend).seconds,2)+50, round(100*(1.0*ttb2)/(end-htend).seconds,2)+50\n",
    "    \n",
    "    # Grab the data from the gamedata\n",
    "    return gamedata[(gamedata['PercDone'] > perc1) & (gamedata['PercDone'] < perc2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Large function that will return to you the relevant game events and then a list of tweets (with their times) \n",
    "from the time period that you specify. Currently works by submitting actual times.\n",
    "\n",
    "Inputs:\n",
    "gp1: The first game participant\n",
    "gp2: The second game participant\n",
    "tp1: Beginning of time period (%H:%M, ex. 7:20), measured by EST\n",
    "tp2: End of time period\n",
    "\n",
    "Outputs:\n",
    "dt1: Dataframe containing all the game events from that period \n",
    "dt2: Dataframe containing the tweets from that period\n",
    "\"\"\"\n",
    "\n",
    "def databytime(gp1, gp2, tp1, tp2):\n",
    "    \n",
    "    # Get the important metadata and define a useful constant\n",
    "    gmdat = pd.read_csv(\"GameMetadata.csv\")\n",
    "    metadat = gmdat[((gmdat['Team1'] == gp1) | (gmdat['Team1'] == gp2)) & ((gmdat['Team2'] == gp1) | (gmdat['Team2'] == gp2))]\n",
    "    eid = metadat['espn_id'].iloc[0]\n",
    "    begin, end = datetime.strptime(metadat['Start'].iloc[0], '%H:%M'), datetime.strptime(metadat['End'].iloc[0], '%H:%M')\n",
    "    lenhalf = 20*60\n",
    "    \n",
    "    # Grab the game data for the time period\n",
    "    gdata = ncaatrendgraph(eid)\n",
    "    dt1 = gamevents(gdata, tp1, tp2, begin, end)\n",
    "    \n",
    "    # Grab the relevant data from the twitter file\n",
    "    fname = '../separated/' + metadat['Filename'].iloc[0]\n",
    "    tweets =  pd.read_csv(fname)\n",
    "    tweets['time_chg'] = tweets['time'].apply(lambda x: x.split(' ')[3])\n",
    "    \n",
    "    indices = []\n",
    "    for num in range(0, len(tweets['time_chg'])):\n",
    "        tweetstamp = datetime.strptime(tweets['time_chg'].iloc[num], \"%H:%M:%S\") - timedelta(hours=4)\n",
    "        if (tweetstamp > begin) and (tweetstamp < end):\n",
    "            if (tweetstamp > datetime.strptime(tp1, '%H:%M')) and (tweetstamp < datetime.strptime(tp2, '%H:%M')):\n",
    "                indices.append(num)\n",
    "    dt2 = tweets[tweets.index.isin(indices)]\n",
    "    \n",
    "    return dt1, dt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Large function that will return to you the relevant game events and then a list of tweets (with their times) \n",
    "from the time period that you specify. Currently works by submitting actual times.\n",
    "\n",
    "Inputs:\n",
    "gp1: The first game participant\n",
    "gp2: The second game participant\n",
    "gtp1: Beginning of game time period (20:00 -- Halftime, 35:00 -- After halftime)\n",
    "gtp2: End of game time period\n",
    "\n",
    "Outputs:\n",
    "dt1: Dataframe containing all the game events from that period \n",
    "dt2: Dataframe containing the tweets from that period\n",
    "\"\"\"\n",
    "def databygametime(gp1, gp2, gtp1, gtp2):\n",
    "    \n",
    "    # Get the important metadata and define a useful constant\n",
    "    gmdat = pd.read_csv(\"GameMetadata.csv\")\n",
    "    metadat = gmdat[((gmdat['Team1'] == gp1) | (gmdat['Team1'] == gp2)) & ((gmdat['Team2'] == gp1) | (gmdat['Team2'] == gp2))]\n",
    "    eid = metadat['espn_id'].iloc[0]\n",
    "    begin, end = datetime.strptime(metadat['Start'].iloc[0], '%H:%M'), datetime.strptime(metadat['End'].iloc[0], '%H:%M')\n",
    "    lenhalf = 20*60\n",
    "    htbegin = begin + timedelta(0, (end-begin).seconds/2 - lenhalf/2)\n",
    "    htend = begin + timedelta(0,(end-begin).seconds/2 + lenhalf/2)\n",
    "    \n",
    "    # Grab the initial data by mapping gametimes to parts of the game\n",
    "    fullgamedat = ncaatrendgraph(eid)\n",
    "    bmin, bsec = gtp1.split(\":\")\n",
    "    emin, esec = gtp2.split(\":\")\n",
    "    btot = int(bmin)*60 + int(bsec)\n",
    "    etot = int(emin)*60 + int(bsec)\n",
    "    maxmin = np.max(fullgamedat['Minutes'])*60\n",
    "    bperc, eperc = (100.0*btot)/maxmin, (100.0*etot)/maxmin\n",
    "    dt1 = fullgamedat[(fullgamedat['PercDone'] >= bperc) & (fullgamedat['PercDone'] <= eperc)]\n",
    "    \n",
    "    # Use the percentages of the game to map gametimes to actual times\n",
    "    acttimes = []\n",
    "    for item in [bperc, eperc]:\n",
    "        hperc = (item*2)/100\n",
    "        if item <= 50.0:\n",
    "            secdelt = round((htbegin-begin).seconds*hperc,0)\n",
    "            acttimes.append(secdelt)\n",
    "        elif item > 50.0:\n",
    "            secdelt = round((end-htend).seconds*(hperc-1.0) + (htend-begin).seconds,0)\n",
    "            acttimes.append(secdelt)\n",
    "    \n",
    "    # Convert the time to usable timedelt objects\n",
    "    tp1, tp2 = begin + timedelta(0,seconds = acttimes[0]), begin + timedelta(0,seconds = acttimes[1])\n",
    "    tp1, tp2 = str(tp1).split(\" \")[1], str(tp2).split(\" \")[1]\n",
    "    \n",
    "    # Get the relevant Tweets over that time period using identical code to before\n",
    "    fname = '../separated/'+metadat['Filename'].iloc[0]\n",
    "    tweets =  pd.read_csv(fname)\n",
    "    tweets['time_chg'] = tweets['time'].apply(lambda x: x.split(' ')[3])\n",
    "    \n",
    "    indices = []\n",
    "    for num in range(0, len(tweets['time_chg'])):\n",
    "        tweetstamp = datetime.strptime(tweets['time_chg'].iloc[num], \"%H:%M:%S\") - timedelta(hours=4)\n",
    "        if (tweetstamp > begin) and (tweetstamp < end):\n",
    "            if (tweetstamp > datetime.strptime(tp1, '%H:%M:%S')) and (tweetstamp < datetime.strptime(tp2, '%H:%M:%S')):\n",
    "                indices.append(num)\n",
    "    dt2 = tweets[tweets.index.isin(indices)]\n",
    "    \n",
    "    return dt1, dt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samp1, samp2 = databygametime('Virginia', 'Syracuse', '22:10', '40:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samp3, samp4 = databytime('Virginia', 'Syracuse', '18:10', '18:20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw = samp4.iloc[120]['text']\n",
    "classifier.classify(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(\"go lions yay team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "negative\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "positive\n",
      "negative\n",
      "positive\n",
      "positive\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "for tw in samp2['text'].iteritems():\n",
    "    res = classifier.classify(tw[1])\n",
    "    if res != 'neutral' and res != 'irrelevant' :\n",
    "        print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
